import { Queue, Worker, Job } from "bullmq";
import { redis, checkRedisHealth, getRedisStatus } from "../lib/redis.js";
import type {
  AnalysisJobData,
  AnalysisJobResult,
  QueueJobOptions,
} from "../types/queue.js";
import { processAnalysisJob } from "../workers/analysis.worker.js";

// Queue configuration
export const QUEUE_NAME = "analysis-queue";
const WORKER_CONCURRENCY = parseInt(process.env.WORKER_CONCURRENCY || "2");
const MAX_QUEUE_SIZE = parseInt(process.env.MAX_QUEUE_SIZE || "1000");
const JOB_TIMEOUT = parseInt(process.env.JOB_TIMEOUT || "300000");
const PRIORITY_LEVELS = {
  HIGH: 10,
  NORMAL: 5,
  LOW: 1,
};

// Queue metrics tracking
let queueMetrics = {
  totalJobsProcessed: 0,
  totalJobsFailed: 0,
  averageProcessingTime: 0,
  lastProcessedAt: 0,
  queueSizeHistory: [] as number[],
  errorCount: 0,
  lastErrorAt: 0,
};

// Create the main analysis queue
export const analysisQueue = new Queue<AnalysisJobData>(QUEUE_NAME, {
  connection: redis,
  defaultJobOptions: {
    attempts: 3,
    backoff: {
      type: "exponential",
      delay: 2000,
    },
    removeOnComplete: 100,
    removeOnFail: 50,
    delay: 0,
  },
});

let integratedWorker: Worker<AnalysisJobData> | null = null;
let autoResumeInterval: NodeJS.Timeout | null = null;

export class WorkerService {
  static async startWorker(): Promise<void> {
    if (integratedWorker) {
      console.log("‚úÖ Worker is already running");
      return;
    }

    try {
      console.log("üöÄ Starting integrated worker...");

      integratedWorker = new Worker<AnalysisJobData>(
        QUEUE_NAME,
        async (job) => {
          console.log(`üöÄ Integrated worker processing job ${job.id}`);
          try {
            const result = await processAnalysisJob(job);
            console.log(`‚úÖ Job ${job.id} completed successfully`);
            return result;
          } catch (error) {
            console.error(`‚ùå Job ${job.id} failed:`, error);
            throw error;
          }
        },
        {
          connection: redis,
          concurrency: WORKER_CONCURRENCY,
        }
      );

      integratedWorker.on("ready", () => {
        console.log("‚úÖ Integrated worker is ready to process jobs");
      });

      integratedWorker.on("active", (job) => {
        console.log(`üîÑ Processing job ${job.id}`);
      });

      integratedWorker.on("completed", (job) => {
        console.log(`‚úÖ Job ${job.id} completed`);
        queueMetrics.totalJobsProcessed++;
        queueMetrics.lastProcessedAt = Date.now();
      });

      integratedWorker.on("failed", (job, err) => {
        console.error(`‚ùå Job ${job?.id} failed:`, err.message);
        queueMetrics.totalJobsFailed++;
        queueMetrics.errorCount++;
        queueMetrics.lastErrorAt = Date.now();
      });

      integratedWorker.on("error", (error) => {
        console.error("‚ùå Integrated worker error:", error);
      });

      this.startAutoResume();

      console.log("‚úÖ Integrated worker started successfully");
    } catch (error) {
      console.error("‚ùå Failed to start integrated worker:", error);
      throw error;
    }
  }

  static async stopWorker(): Promise<void> {
    if (!integratedWorker) {
      console.log("‚ÑπÔ∏è Worker is not running");
      return;
    }

    try {
      console.log("üîÑ Stopping integrated worker...");

      this.stopAutoResume();

      await integratedWorker.close();
      integratedWorker = null;

      console.log("‚úÖ Integrated worker stopped successfully");
    } catch (error) {
      console.error("‚ùå Failed to stop integrated worker:", error);
      throw error;
    }
  }

  static isWorkerRunning(): boolean {
    return integratedWorker !== null;
  }

  static getWorkerStatus() {
    return {
      isRunning: this.isWorkerRunning(),
      concurrency: WORKER_CONCURRENCY,
      queueName: QUEUE_NAME,
      autoResumeActive: autoResumeInterval !== null,
    };
  }

  static startAutoResume(): void {
    if (autoResumeInterval) {
      return;
    }

    console.log("üîÑ Starting auto-resume functionality...");

    autoResumeInterval = setInterval(async () => {
      try {
        const isPaused = await analysisQueue.isPaused();
        if (isPaused) {
          console.log("üîÑ Queue is paused, attempting to resume...");
          await analysisQueue.resume();
          console.log("‚úÖ Queue resumed successfully");
        }
      } catch (error) {
        console.error("‚ùå Error in auto-resume:", error);
      }
    }, 30000); // Check every 30 seconds

    console.log("‚úÖ Auto-resume functionality started");
  }

  static stopAutoResume(): void {
    if (autoResumeInterval) {
      clearInterval(autoResumeInterval);
      autoResumeInterval = null;
      console.log("‚úÖ Auto-resume functionality stopped");
    }
  }

  static async processWaitingJobs() {
    try {
      const waiting = await analysisQueue.getWaiting();

      if (waiting.length > 0) {
        // Ensure queue is resumed if there are waiting jobs
        const isPaused = await analysisQueue.isPaused();
        if (isPaused) {
          await analysisQueue.resume();
          console.log("‚úÖ Queue resumed to process waiting jobs");
        }
        return waiting.length;
      }

      return 0;
    } catch (error) {
      console.error("Error processing waiting jobs:", error);
      return 0;
    }
  }
}
export class QueueService {
  static async addJob(
    jobData: AnalysisJobData,
    options: QueueJobOptions = {}
  ): Promise<Job<AnalysisJobData>> {
    const isRedisHealthy = await checkRedisHealth();
    if (!isRedisHealthy) {
      throw new Error(
        "Redis connection is not available. Please try again later."
      );
    }

    const waiting = await analysisQueue.getWaiting();
    const active = await analysisQueue.getActive();
    const currentQueueSize = waiting.length + active.length;

    if (currentQueueSize >= MAX_QUEUE_SIZE) {
      throw new Error(
        `Queue is full. Current size: ${currentQueueSize}/${MAX_QUEUE_SIZE}. Please try again later.`
      );
    }

    const priority = this.determineJobPriority(jobData, options.priority);

    console.log(`üìù Adding job to queue with data:`, jobData);
    const job = await analysisQueue.add("analysis", jobData, {
      priority,
      delay: options.delay || 0,
      attempts: options.attempts || 3,
      backoff: options.backoff || {
        type: "exponential",
        delay: 2000,
      },
    });
    console.log(`Job added to queue with ID: ${job.id}`);

    // Update queue size history
    queueMetrics.queueSizeHistory.push(currentQueueSize + 1);
    if (queueMetrics.queueSizeHistory.length > 100) {
      queueMetrics.queueSizeHistory.shift();
    }

    return job as Job<AnalysisJobData>;
  }

  private static determineJobPriority(
    jobData: AnalysisJobData,
    userPriority?: number
  ): number {
    if (userPriority !== undefined) {
      return Math.max(1, Math.min(10, userPriority));
    }

    if (jobData.userId && /^[\+\d]/.test(jobData.userId)) {
      return PRIORITY_LEVELS.HIGH;
    }

    if (jobData.inputType === "url") {
      return PRIORITY_LEVELS.NORMAL;
    }

    return PRIORITY_LEVELS.LOW;
  }

  static async getJobStatus(jobId: string): Promise<any> {
    const job = await analysisQueue.getJob(jobId);

    if (!job) {
      return { error: "Job not found" };
    }

    const state = await job.getState();
    const progress = job.progress;
    const analysis = (await job.returnvalue) ?? {
      jobId: parseInt(job.id as string),
      status: state === "failed" ? "failed" : "pending",
    };
    const failedReason = job.failedReason;
    const timeToComplete = job.finishedOn
      ? job.finishedOn - job.timestamp
      : null;

    return {
      analysis,
      failedReason,
      metadata: {
        timestamp: job.timestamp,
        processedOn: job.processedOn,
        finishedOn: job.finishedOn,
        timeToComplete,
        ...(state && { state }),
        ...(typeof progress === "number" ? { progress } : {}),
      },
    };
  }

  static async getQueueStats() {
    const waiting = await analysisQueue.getWaiting();
    const active = await analysisQueue.getActive();
    const completed = await analysisQueue.getCompleted();
    const failed = await analysisQueue.getFailed();
    const redisStatus = getRedisStatus();

    const totalJobs =
      queueMetrics.totalJobsProcessed + queueMetrics.totalJobsFailed;
    const failureRate =
      totalJobs > 0 ? (queueMetrics.totalJobsFailed / totalJobs) * 100 : 0;

    return {
      waiting: waiting.length,
      active: active.length,
      completed: completed.length,
      failed: failed.length,
      total: waiting.length + active.length + completed.length + failed.length,

      totalJobsProcessed: queueMetrics.totalJobsProcessed,
      totalJobsFailed: queueMetrics.totalJobsFailed,
      failureRate: Math.round(failureRate * 100) / 100,
      averageProcessingTime: Math.round(queueMetrics.averageProcessingTime),
      lastProcessedAt: queueMetrics.lastProcessedAt,

      redisStatus,
      workerConcurrency: WORKER_CONCURRENCY,
      maxQueueSize: MAX_QUEUE_SIZE,
      currentQueueUtilization: Math.round(
        ((waiting.length + active.length) / MAX_QUEUE_SIZE) * 100
      ),

      queueSizeHistory: queueMetrics.queueSizeHistory.slice(-20),
      errorCount: queueMetrics.errorCount,
      lastErrorAt: queueMetrics.lastErrorAt,
    };
  }

  static async getHealthStatus() {
    const redisHealthy = await checkRedisHealth();
    const stats = await this.getQueueStats();

    const health = {
      status: redisHealthy && stats.failureRate < 20 ? "healthy" : "unhealthy",
      redis: redisHealthy ? "connected" : "disconnected",
      queue: stats.currentQueueUtilization < 80 ? "normal" : "overloaded",
      workers: stats.active <= WORKER_CONCURRENCY ? "normal" : "overloaded",
      errors: stats.failureRate < 10 ? "normal" : "high",
      timestamp: new Date().toISOString(),
    };

    return health;
  }

  static getPerformanceMetrics() {
    return {
      ...queueMetrics,
      workerConcurrency: WORKER_CONCURRENCY,
      maxQueueSize: MAX_QUEUE_SIZE,
      jobTimeout: JOB_TIMEOUT,
    };
  }

  static async cleanOldJobs() {
    const completed = await analysisQueue.clean(
      24 * 60 * 60 * 1000,
      100,
      "completed"
    );
    const failed = await analysisQueue.clean(24 * 60 * 60 * 1000, 50, "failed");
  }

  static async pauseQueue() {
    await analysisQueue.pause();
  }

  static async resumeQueue() {
    await analysisQueue.resume();
  }

  static async adjustConcurrency(newConcurrency: number) {
    if (newConcurrency < 1 || newConcurrency > 10) {
      throw new Error("Concurrency must be between 1 and 10");
    }
  }

  static async getOptimalConcurrency(): Promise<number> {
    const stats = await this.getQueueStats();
    const queueLoad = stats.currentQueueUtilization;

    if (queueLoad > 80) {
      return Math.min(WORKER_CONCURRENCY + 2, 10);
    } else if (queueLoad < 20) {
      return Math.max(WORKER_CONCURRENCY - 1, 1);
    }

    return WORKER_CONCURRENCY;
  }

  static async autoScale() {
    try {
      const optimalConcurrency = await this.getOptimalConcurrency();
      if (optimalConcurrency !== WORKER_CONCURRENCY) {
        await this.adjustConcurrency(optimalConcurrency);
      }
    } catch (error) {
      console.error("‚ùå Auto-scaling failed:", error);
    }
  }

  static async shutdown() {
    try {
      await WorkerService.stopWorker();

      await analysisQueue.pause();

      const activeJobs = await analysisQueue.getActive();
      if (activeJobs.length > 0) {
        let waitTime = 0;
        const maxWaitTime = 30000;
        const checkInterval = 1000;

        while (waitTime < maxWaitTime) {
          const stillActive = await analysisQueue.getActive();
          if (stillActive.length === 0) {
            break;
          }

          await new Promise((resolve) => setTimeout(resolve, checkInterval));
          waitTime += checkInterval;
        }
      }

      await analysisQueue.close();
    } catch (error) {
      console.error("Error during queue shutdown:", error);
      try {
        analysisQueue.close();
      } catch (forceError) {
        console.error("Force close failed:", forceError);
      }
    }
  }
}

let autoScaleInterval: NodeJS.Timeout | null = null;
let monitoringInterval: NodeJS.Timeout | null = null;

export function startAutoScaling() {
  if (autoScaleInterval) return;

  autoScaleInterval = setInterval(async () => {
    try {
      await QueueService.autoScale();
    } catch (error) {
      console.error("Auto-scaling error:", error);
    }
  }, 2 * 60 * 1000);
}

export function stopAutoScaling() {
  if (autoScaleInterval) {
    clearInterval(autoScaleInterval);
    autoScaleInterval = null;
  }
}

export function startMonitoring() {
  if (monitoringInterval) return;

  monitoringInterval = setInterval(async () => {
    try {
      const health = await QueueService.getHealthStatus();
      const stats = await QueueService.getQueueStats();
      const workerStatus = WorkerService.getWorkerStatus();

      if (health.status === "unhealthy") {
        console.warn(
          `üö® System unhealthy: Redis=${health.redis}, Queue=${health.queue}, Workers=${health.workers}, Errors=${health.errors}`
        );
      }

      if (!workerStatus.isRunning) {
        try {
          await WorkerService.startWorker();
        } catch (error) {
          console.error("‚ùå Failed to restart worker:", error);
        }
      }

      if (stats.currentQueueUtilization > 90) {
        console.warn(
          `üö® High queue utilization: ${stats.currentQueueUtilization}%`
        );
      }
    } catch (error) {
      console.error("‚ùå Monitoring error:", error);
    }
  }, 30 * 1000);
}

export function stopMonitoring() {
  if (monitoringInterval) {
    clearInterval(monitoringInterval);
    monitoringInterval = null;
  }
}

process.on("SIGTERM", async () => {
  stopAutoScaling();
  stopMonitoring();
  await QueueService.shutdown();
  process.exit(0);
});

process.on("SIGINT", async () => {
  stopAutoScaling();
  stopMonitoring();
  await QueueService.shutdown();
  process.exit(0);
});

export default QueueService;
